{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **ZYNGA HACKATHON SUBMISSION**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qL81OLR4BQSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install easyocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UUB8L-NeDlFx",
        "outputId": "376a37ad-2294-448b-c680-3edf00c750cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting easyocr\n",
            "  Downloading easyocr-1.7.1-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.18.0+cu121)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from easyocr) (4.10.0.84)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.11.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from easyocr) (9.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.19.3)\n",
            "Collecting python-bidi (from easyocr)\n",
            "  Downloading python_bidi-0.4.2-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from easyocr) (6.0.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.4)\n",
            "Collecting pyclipper (from easyocr)\n",
            "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja (from easyocr)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.15.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->easyocr)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->easyocr)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->easyocr)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->easyocr)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->easyocr)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->easyocr)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->easyocr)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->easyocr)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->easyocr)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->easyocr)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->easyocr)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->easyocr)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from python-bidi->easyocr) (1.16.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2024.5.22)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (24.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easyocr) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->easyocr) (1.3.0)\n",
            "Installing collected packages: pyclipper, ninja, python-bidi, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, easyocr\n",
            "Successfully installed easyocr-1.7.1 ninja-1.11.1.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pyclipper-1.3.0.post5 python-bidi-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79CRMG1mAvdc",
        "outputId": "f0a59507-35c1-4b9c-9040-b2cd385bd496"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CODE SET [ 1 - 7 ]"
      ],
      "metadata": {
        "id": "OUXtg_IfR-aR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generalised Approach for finding similarity in images"
      ],
      "metadata": {
        "id": "HdPj_o76tm9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def build_cnn(input_shape):\n",
        "    input_img = Input(shape=input_shape)\n",
        "    x = Conv2D(32, (3, 3), activation='relu')(input_img)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Flatten()(x)\n",
        "    cnn_model = Model(inputs=input_img, outputs=x)\n",
        "    return cnn_model\n",
        "\n",
        "\n",
        "def extract_features(model, image):\n",
        "    image = cv2.resize(image, (64, 64))\n",
        "    image = image.astype('float32') / 255.0\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    return model.predict(image)\n",
        "\n",
        "\n",
        "def calculate_similarity(feature1, feature2):\n",
        "    return cosine_similarity(feature1, feature2)[0][0]\n",
        "\n",
        "\n",
        "def load_image(file_path):\n",
        "    return cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    input_shape = (64, 64, 1)\n",
        "    cnn = build_cnn(input_shape)\n",
        "\n",
        "    main_image_path = input(\"Enter the path for the main image: \")\n",
        "    main_image = load_image(main_image_path)\n",
        "    if main_image is None:\n",
        "        print(\"Failed to load the main image.\")\n",
        "        return\n",
        "\n",
        "    test_image1_path = input(\"Enter the path for the first test image: \")\n",
        "    test_image1 = load_image(test_image1_path)\n",
        "    if test_image1 is None:\n",
        "        print(\"Failed to load the first test image.\")\n",
        "        return\n",
        "\n",
        "    test_image2_path = input(\"Enter the path for the second test image: \")\n",
        "    test_image2 = load_image(test_image2_path)\n",
        "    if test_image2 is None:\n",
        "        print(\"Failed to load the second test image.\")\n",
        "        return\n",
        "\n",
        "    feature_main = extract_features(cnn, main_image)\n",
        "    feature_test1 = extract_features(cnn, test_image1)\n",
        "    feature_test2 = extract_features(cnn, test_image2)\n",
        "\n",
        "    similarity1 = calculate_similarity(feature_main, feature_test1)\n",
        "    similarity2 = calculate_similarity(feature_main, feature_test2)\n",
        "\n",
        "    print(f\"Similarity percentages: [{similarity1 * 100:.2f}%, {similarity2 * 100:.2f}%]\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnpsQFedoDVE",
        "outputId": "9e318d93-277a-4b81-9e64-475a4917833e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the path for the main image: /content/Image.png\n",
            "Enter the path for the first test image: /content/Test1.png\n",
            "Enter the path for the second test image: /content/Test2.png\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Similarity percentages: [99.58%, 93.63%]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Approach to check similarity for all set from 1 to 7 is provided in a separate python file named as \"Set1_to_Set7\"**\n"
      ],
      "metadata": {
        "id": "huwvdsmsqbuK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CODE SET 8"
      ],
      "metadata": {
        "id": "_B1HNgzqTBXo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GENERALISED CODE TO EXTRACT THE TOTAL WIN AMOUNT FROM THE GIVEN IMAGE"
      ],
      "metadata": {
        "id": "vKSLtgyurNDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def build_cnn(input_shape):\n",
        "    input_img = Input(shape=input_shape)\n",
        "    x = Conv2D(32, (3, 3), activation='relu')(input_img)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    cnn_model = Model(inputs=input_img, outputs=x)\n",
        "    return cnn_model\n",
        "input_shape = (224, 224, 3)\n",
        "cnn_model = build_cnn(input_shape)\n",
        "cnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVOzRqXq905_",
        "outputId": "513edce7-4c06-43f2-968b-b32a8ab1a1ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 222, 222, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPooli  (None, 111, 111, 32)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 109, 109, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_25 (MaxPooli  (None, 54, 54, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 186624)            0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 128)               23888000  \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23915648 (91.23 MB)\n",
            "Trainable params: 23915648 (91.23 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_total_win(results):\n",
        "    for result in results:\n",
        "        text = result[1]\n",
        "        if 'TOTAL WIN' in text:\n",
        "            parts = text.split()\n",
        "            # Check if the first part is a number\n",
        "            if parts and parts[0].replace(',', '').isdigit():\n",
        "                return parts[0]\n",
        "    return None"
      ],
      "metadata": {
        "id": "dsL30ld0rIpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***code for the result generation for SET 8 is provided in the separate file named \"SET8\". ***"
      ],
      "metadata": {
        "id": "DLee9oUHrgzO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CODE SET 9"
      ],
      "metadata": {
        "id": "pJCeRK0Lav_9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***IN SET9 our Task is to find the amount associated with \"BET\" so we desided to create a dataset for getting better results***"
      ],
      "metadata": {
        "id": "1cYqisa_sPUN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we played the game and took screenshots while playing to create a dataset and then finally formed the output_directory to get our desired area of interest"
      ],
      "metadata": {
        "id": "EpJrZ0UgsyKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Creation with Region of Interset"
      ],
      "metadata": {
        "id": "_diR-h6osIpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import easyocr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "input_dir = '/content/drive/My Drive/without box'\n",
        "output_dir = '/content/drive/My Drive/Zynga comp'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "reader = easyocr.Reader(['en'], gpu=False)\n",
        "def bbox_distance(bbox1, bbox2):\n",
        "    center1 = np.mean(bbox1, axis=0)\n",
        "    center2 = np.mean(bbox2, axis=0)\n",
        "    return np.linalg.norm(center1 - center2)\n",
        "for image_name in os.listdir(input_dir):\n",
        "    image_path = os.path.join(input_dir, image_name)\n",
        "    img = cv2.imread(image_path)\n",
        "    text_ = reader.readtext(img)\n",
        "    threshold = 0.25\n",
        "    bet_bbox = None\n",
        "    closest_num = None\n",
        "    min_dist = float('inf')\n",
        "    for t_, t in enumerate(text_):\n",
        "        bbox, text, score = t\n",
        "        if score > threshold:\n",
        "            top_left = tuple(map(int, bbox[0]))\n",
        "            bottom_right = tuple(map(int, bbox[2]))\n",
        "            if text.upper() == \"BET\":\n",
        "                bet_bbox = bbox\n",
        "            if any(c.isdigit() for c in text):\n",
        "                cv2.rectangle(img, top_left, bottom_right, (0, 255, 0), 2)\n",
        "                if bet_bbox:\n",
        "                    dist = bbox_distance(bet_bbox, bbox)\n",
        "                    if dist < min_dist:\n",
        "                        min_dist = dist\n",
        "                        closest_num = text\n",
        "            else:\n",
        "                cv2.rectangle(img, top_left, bottom_right, (0, 0, 255), 2)\n",
        "    annotated_image_path = os.path.join(output_dir, image_name)\n",
        "    cv2.imwrite(annotated_image_path, img)\n",
        "    if closest_num:\n",
        "        print(f\"The closest numerical value to 'BET' in {image_name} is: {closest_num}\")\n",
        "    else:\n",
        "        print(f\"No numerical value found close to 'BET' in {image_name}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ7IGbYcBoe5",
        "outputId": "3628d27d-36ba-4371-cd10-bc4a89412bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Using CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The closest numerical value to 'BET' in Test22.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test21.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test8.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test7.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test68.jpeg is: 25,000,000\n",
            "The closest numerical value to 'BET' in Test9.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test38.jpeg is: 40,000,000\n",
            "The closest numerical value to 'BET' in Test20.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test67.jpeg is: 10,000,000\n",
            "The closest numerical value to 'BET' in Test2.png is: 500,000,000,000\n",
            "The closest numerical value to 'BET' in Test37.jpeg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test17.jpg is: 10,000,000\n",
            "The closest numerical value to 'BET' in Test19.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test15.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test14.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test13.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test10.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test16.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test11.jpg is: 15,000,000\n",
            "The closest numerical value to 'BET' in Test18.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test1.png is: 2,500,000,000,000\n",
            "The closest numerical value to 'BET' in Test12.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test32.jpg is: 15,000,000\n",
            "The closest numerical value to 'BET' in Test31.jpg is: 15,000,000\n",
            "The closest numerical value to 'BET' in Test30.jpg is: 15,000,000\n",
            "The closest numerical value to 'BET' in Test3.png is: 500,000,000,000\n",
            "The closest numerical value to 'BET' in Test29.jpg is: 15,000,000\n",
            "The closest numerical value to 'BET' in Test28.jpg is: 15,000,000\n",
            "The closest numerical value to 'BET' in Test27.jpg is: 15,000,000\n",
            "The closest numerical value to 'BET' in Test26.jpg is: 15,000,000\n",
            "The closest numerical value to 'BET' in Test25.jpg is: 15,000,000\n",
            "The closest numerical value to 'BET' in Test24.jpg is: 15,000,000\n",
            "The closest numerical value to 'BET' in Test23.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test39.jpg is: 25,000,000\n",
            "The closest numerical value to 'BET' in Test36.jpg is: 25,000,000\n",
            "The closest numerical value to 'BET' in Test35.jpg is: 25,000,000\n",
            "The closest numerical value to 'BET' in Test34.jpg is: 25,000,000\n",
            "The closest numerical value to 'BET' in Test33.jpg is: 15,000,000\n",
            "The closest numerical value to 'BET' in Test5.png is: 500,000,000,000\n",
            "The closest numerical value to 'BET' in Test49.jpg is: 50,000,000\n",
            "The closest numerical value to 'BET' in Test48.jpg is: 50,000,000\n",
            "The closest numerical value to 'BET' in Test47.jpg is: 50,000,000\n",
            "The closest numerical value to 'BET' in Test46.jpg is: 50,000,000\n",
            "The closest numerical value to 'BET' in Test45.jpg is: 25,000,000\n",
            "The closest numerical value to 'BET' in Test44.jpg is: 25,000,000\n",
            "The closest numerical value to 'BET' in Test43.jpg is: 25,000,000\n",
            "The closest numerical value to 'BET' in Test42.jpg is: 25,000,000\n",
            "The closest numerical value to 'BET' in Test41.jpg is: 25,000,000\n",
            "The closest numerical value to 'BET' in Test40.jpg is: 25,000,000\n",
            "The closest numerical value to 'BET' in Test4.png is: 2,500,000,000,000\n",
            "The closest numerical value to 'BET' in Test54.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test53.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test52.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test51.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test50.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test65.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test64.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test63.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test62.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test61.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test60.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test6.png is: 2,500,000,000,000\n",
            "The closest numerical value to 'BET' in Test59.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test58.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test57.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test56.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test55.jpg is: 7,500,000\n",
            "The closest numerical value to 'BET' in Test66.jpg is: 7,500,000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "def create_model(input_shape, num_classes):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "    return model\n",
        "input_shape = (128, 128, 3)\n",
        "num_classes = 1\n",
        "model = create_model(input_shape, num_classes)\n",
        "model.summary()\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nFTLbdPggqe",
        "outputId": "2f7f8ec4-d897-4aee-c34c-399334971e9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_18 (Conv2D)          (None, 126, 126, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPooli  (None, 63, 63, 32)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 61, 61, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPooli  (None, 30, 30, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 28, 28, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPooli  (None, 14, 14, 128)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               3211392   \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3304769 (12.61 MB)\n",
            "Trainable params: 3304769 (12.61 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "dataset_dir = output_dir\n",
        "image_paths = [os.path.join(dataset_dir, fname) for fname in os.listdir(dataset_dir) if fname.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "labels = [0] * len(image_paths)\n",
        "train_paths, val_paths, train_labels, val_labels = train_test_split(image_paths, labels, test_size=0.2, random_state=42)\n",
        "print(f\"Total images: {len(image_paths)}\")\n",
        "print(f\"Training images: {len(train_paths)}\")\n",
        "print(f\"Validation images: {len(val_paths)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkQ7628thiQk",
        "outputId": "573ea506-ff35-4bbb-ac85-cc7773617113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images: 69\n",
            "Training images: 55\n",
            "Validation images: 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "def create_model(input_shape):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "input_shape = (128, 128, 3)\n",
        "batch_size = 32\n",
        "num_classes = 1\n",
        "model = create_model(input_shape)\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lN49WdDoiStc",
        "outputId": "b6110477-0fe0-4412-d871-b9445cd4ef32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_21 (Conv2D)          (None, 126, 126, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPooli  (None, 63, 63, 32)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 61, 61, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPooli  (None, 30, 30, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 28, 28, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPooli  (None, 14, 14, 128)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               3211392   \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3304769 (12.61 MB)\n",
            "Trainable params: 3304769 (12.61 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = max(1, len(train_paths) // batch_size)\n",
        "validation_steps = max(1, len(val_paths) // batch_size)\n",
        "history = model.fit(\n",
        "    custom_data_generator(train_paths, train_labels, batch_size, 128, 128),\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=10,\n",
        "    validation_data=custom_data_generator(val_paths, val_labels, batch_size, 128, 128),\n",
        "    validation_steps=validation_steps\n",
        ")\n",
        "model.save('my_model.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-eI3I_miIkN",
        "outputId": "a4a31b2f-7f65-46d6-9513-71e83e4949e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6675 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 5.5101e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 4s 4s/step - loss: 5.2720e-06 - accuracy: 1.0000 - val_loss: 8.7361e-10 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 8.4602e-10 - accuracy: 1.0000 - val_loss: 3.7389e-10 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 5.2060e-12 - accuracy: 1.0000 - val_loss: 1.5497e-15 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.5472e-15 - accuracy: 1.0000 - val_loss: 1.2836e-17 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 4.8485e-18 - accuracy: 1.0000 - val_loss: 2.2853e-18 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 4s 4s/step - loss: 1.1587e-23 - accuracy: 1.0000 - val_loss: 4.5179e-27 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.4473e-23 - accuracy: 1.0000 - val_loss: 2.1014e-25 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 4s 4s/step - loss: 4.1329e-31 - accuracy: 1.0000 - val_loss: 5.6513e-30 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "val_loss, val_accuracy = model.evaluate(val_generator, steps=validation_steps)\n",
        "\n",
        "print(f\"Validation loss: {val_loss:.4f}\")\n",
        "print(f\"Validation accuracy: {val_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6aq0gUUlOqL",
        "outputId": "09183617-baec-42aa-82fd-b35c984594bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 177ms/step - loss: 1.2320e-32 - accuracy: 1.0000\n",
            "Validation loss: 0.0000\n",
            "Validation accuracy: 1.0000\n"
          ]
        }
      ]
    }
  ]
}